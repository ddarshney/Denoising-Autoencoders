# Denoising-Autoencoders

Due to advancement in technology we might have a large amount of the data but there is always concern about the usability. For example, in medical images like X-rays, MRI, CT scans, Ultrasound, etc., when original images are put in the paper, the quality degrades, due to which the accuracy of the decision model degrades. These images are susceptible to noise.

Image denoising is required to suppress noise from noise-contaminated images,and hence, is an important preprocessing step in image analysis. There are many different techniques and methods which can be used for performing denoising such as applying Median, Gaussian, Average, Bilateral Filters, etc. However, they don't necessarily perform well in denoising images without losing much information and hence, an algorithm is needed that can outperform all the other methods that have been proposed.

![image](https://user-images.githubusercontent.com/68664921/148658793-b59db98d-ec9b-4535-9b57-341600302a3f.png)
